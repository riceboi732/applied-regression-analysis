---
title: "Stat 230 HW 7"
author: 'Name: Victor Huang'
output:
  html_document: default
  pdf_document: default
---
```{r, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=FALSE, comment=NULL, warning = FALSE, message = FALSE)
library(Sleuth3)
library(ggplot2)
library(ggResidpanel)
library(dplyr)
library(broom)
library(knitr)
```


### worked with: None


Homework 6 is due **by 3pm Wednesday, Nov. 10**. Please complete the assignment in this Markdown document, filling in your answers and R code below.  I didn't create answer and R chunk fields like I did with homework 1, but please fill in your answers and R code in the same manner as hw 1.  Submit  a hard copy of the **compiled pdf or word doc** either

  - in class 
  - in drop-in office hours 
  - in the paper holder outside my CMC 222 office door

Tips for using Markdown with homework sets:

- Work through a problem by putting your R code into R chunks in this .Rmd. Run the R code to make sure it works, then knit the .Rmd to verify they work in that environment.
    - Make sure you load your data in the .Rmd and include any needed `library` commands. 
- Feel free to edit or delete  questions, instructions, or code provided in this file when producing your homework solution. 
- For your final document, you can change the output type from `html_document` to `word_document` or `pdf_document`. These two to output types are better formatted for printing. 
  - on maize: you may need to allow for pop-ups from this site 
- If you want to knit to pdf while running Rstudio from your computer (*not* from maize), you  will need a LaTeX compiler installed on your computer. This could be [MiKTeX](https://miktex.org/), [MacTeX](http://www.tug.org/mactex/) (mac), or TinyTex. The latter is installed in R: first install the R package `tinytex`, then run the command `tinytex::install_tinytex()` to install this software. 
  - If you are using maize, you don't need to install anything to knit to pdf!


-------------------------


## Problem 1: Salk Vaccine Field Trials of 1954
The Salk Vaccine Trial is one of the most famous, and largest, clinical trial ever conducted. This study showed that a vaccine composed of killed polio viruses could inoculate people against polio.  Another major outcome of this trial was to "prove" the benefit of placebo-controlled, randomized experimental designs that are now the "gold standard" in clinical trials. In this problem you will analyze the data from this experiment. 

Experimental Design: In 11 states parents of first, second, and third graders were asked for permission to enroll their child into the trial (consent: 401,974 said yes and 338,778 said no). Then, of the 401,974 students who had parental consent, about half (200,745) were randomly assigned to be injected with the vaccine while the other half (201,229) were injected with a saline solution (vaccine: yes or no). The R commands below give the number of polio cases (`y`) out of the number of kids (`m`) in each combination of `consent` and `vaccine`. Obviously, no kids were given the vaccine if they did not have parental consent, so there are only 3 combinations of these variables. 

```{r}
m <- c(200745, 201229, 338778)
y <- c(33,115,121)
consent<- c("yes","yes","no")
vaccine <- c("yes","no","no")
salk<- data.frame(m,y,consent,vaccine)
salk
```

### (1a) Fit the binomial logistic regression of `y` on `consent` and `vaccine`. After accounting for parental consent, what effect does the vaccine have on the odds of getting polio? Compute and interpret a 95% confidence interval for this effect. (Note that this is a causal effect since the vaccine was randomly assigned to consenting kids.)

```{r}
salk_glm <- glm(y/m ~ consent + vaccine, family = "binomial", weights = m , data= salk)
tidy(salk_glm, conf.int=TRUE)
```
$$odds(consent,vaccine) = e^{-7.9369525 + 0.4702575(consentyes) - 1.2464237(vaccineyes)} = e^{-7.9369525}e^{0.4702575(consentyes)}e^{-1.2464237(vaccineyes)}$$
$$odds(vaccineyes = 1) = e^{-1.2464237(1)} = 0.2875313$$

With parental consent, the vaccine results in a multiplicative change of 0.2875313 (meaning that the vaccine decreases the odss of getting polio by 71.24687%) (95% CI from 58.2$ to 80.8%)

### (1b) After accounting for vaccine treatment, what effect does  parental consent have on the odds of getting polio? Compute and interpret a 95% confidence interval for this effect. (Note that this is not a causal effect since parental consent was not randomly assigned to kids.)

$$odds(consentyes = 1) = e^{0.4702575(1)} = 1.600406$$

After vaccine treatment, parental consent has a 1.600406 multiplicative factor on the odds of the child getting polio. Meaning that parental consent leads to a 60% increase of the chance for their child to get polio. (95% CI from 23.9% to 106.6%)

### (1c) Some details about polio: Researchers knew that when raised in unsanitary conditions, babies could actually build a natural immunity to polio when mildly exposed to it. This immunity made them less susceptible to the severe strain of the disease as they grow. Children who were protected from this exposure by clean surroundings did not usually build this immunity and were more likely to get the disease.  Demographic data collected during the experiment showed that kids with no parental consent had similar family backgrounds. Records showed that these kids tended to come from lower income households compared to kids whose parents did consent. Use this information to try to explain the parental consent effect you quantified in part (b). 

Since the kids who's parents who did not give consent to the vaccine have tended to live in lower income households, they were more likely to have built a natural immunity against polio when mildly exposed. As such, even without parental consent some of the kids can still be considered to have a "pseudo vaccine" through this exposure. As such, the parental consent effect in part (b) is somewhat mitigated by the fact that their kids have most likely built up a resistance to polio from living in a low-income background. Also, the parents who did consent to the vaccine, half of them got a placebo (saline solution) instead of the actual vaccine, which also accounts for why those who consented and did not get the vaccine to have a higher chance of getting polio. 

-----------------------------------------


## Problem 2: Vitamin C Chapter 21 exercise 12 (a-c)
You'll need to enter the data for this example by hand. You can use code similar to that used in Problem 2 above to do so. 

a.
\newline
```{r}
m <- c(411, 407)
y <- c(335,302)
placebo <- c("yes","no")
ex2112 <- data.frame(m,y,placebo)
ex2112
ex2112_glm <- glm(y/m ~ placebo, family = "binomial", weights = m , data= ex2112)
tidy(ex2112_glm, conf.int=TRUE)
```
$$logit(\pi_{i}) = 1.0564667 + 0.4269305(placeboyes)$$
Using R and the logit function, we are able to obtain a value of 0.4269305 for the $\beta_{1}$ value with a 95% CI between 0.09477341 and 0.7628385
\newline
\newline
b.
\newline
Using our function from above, we see that the odds of cold for the placebo group relative to the odds of a cold for the
vitamin C group is differentiated by a factor of $e^{\beta_{1}} = 1.532546$. What this means is that for every 1.532546 people in the placebo group that catch the cold, 1 person from the Vitamin C group will catch the cold.
\newline
\newline
c.
\newline
The answer for part b (odds = 1.532546) matches the answer concluded from Display 18.9
-----------------------------------------



## Problem 3: Vitamin C:  ch. 21 exercise 13 (a-c)
The data for this problem is `ex2113`.

a.
\newline
```{r}
ex2113 <- ex2113
ex2113_glm <- glm(WithoutIllness/Number ~ Dose, family = "binomial", weights = Number, data = ex2113)
tidy(ex2113_glm, conf.int=TRUE)
plot(c(0, 0.25, 1, 2), c(-1.200, -1.209, -1.235, -1.270))
summary(ex2113_glm, conf.int = TRUE)
1-pchisq(0.530, df=2)
anova(ex2113_glm, test = "Chisq")
1-pchisq(0.23845, df=2)
```
$$logit(\pi(X_{i})) = -1.20031411 - 0.03464716(Dose)$$
$$logit(dose = 0) = -1.20031411 - 0.03464716(0) = -1.20031411$$
$$logit(dose = 0.25) = -1.20031411 - 0.03464716(0.25) = -1.208976$$
$$logit(dose = 1) = -1.20031411 - 0.03464716(1) = -1.234961$$
$$logit(dose = 2) = -1.20031411 - 0.03464716(2) = -1.269608$$

b.
\newline
Our $\beta_{0}$ value is -1.2 and our $\beta_{1}$ value is -0.035 with SE 0.062 and 0.071 respectively. After conducting goodness tests, we get $G^2 = 0.530$ with a p-values of 0.767. The Wald test has a z-value of -0.487 and a p-val of 0.626. The drop test for the $\beta_{1} = 0$ is 0.888. 
\newline
\newline
c.
\newline
Since all of ours -p-values are greater than 0.05, we failt o reject the null hypothesis. As such, we can say that the binomial logistic model is a adequet and that there is sufficient evidence to calim that the odds for getting a cold are associated with the dose of vitamin C administrated. 
-----------------------------------------



## Problem 4: Death Penalty and Race:  ch. 21 exercise 10 (a-e)
This data set is `case1902`.

```{r}
caese1902 <- case1902
case1902_glm <- glm(Death/(Death + NoDeath) ~ Victim + Aggravation, family = binomial, 
                    weights = (Death + NoDeath), data=case1902)
summary(case1902_glm, conf.int = TRUE)
proportion <- case1902$Death / (caese1902$Death + caese1902$NoDeath)
case1902_aug <- augment(data = case1902, case1902_glm, type.predict = "response")
ggplot(case1902_aug, aes(x = Aggravation, y = log((Death + .5)/(prop - Death + .5)))) + 
   geom_line(aes(y = .fitted, linetype=Victim))
1-pchisq(3.8816, df=9)
tidy(case1902_glm, conf.int = TRUE)
```
\newline
\newline
b.
\newline
$$logit(\pi(X_i)) = -6.676 + 1.540Aggravation + 1.811VictimWhite$$
\newline
\newline
c.
\newine
We get a $G^2$ value of 3.8816 and a correspondng p-value of 0.9190309
\newline
\newline
d.
\newline
Our Wald test show that we get a indicator variable with value 3.366 with a p-value of 0.000732. Since we have a p-value less than 0.05, we can conclude that the indicator variable is significant and is not equal to 0.
\newline
\newline
e.
\newline
After accounting for the aggravation level of the crime, we are 95% confident that the odds of the death sentence for white-victim murderers are 2.230 to 18.729 times higher relative to black-victim murderers.
-----------------------------------------


## Problem 5: Space Shuttle Challenger (article assigned reading)  
The data set `challenger.csv` contains the o-ring data presented in Table 1 of the Dalal, Fowlkes, and Hoadley paper. The observations (rows) in this data set are flights taken under various conditions. The variables are `temperature` (ambienent temp in Farenheit), `pressure` (field leak-check pressure), `nozzle.pres` (nozzle leak-check pressure), `damaged` (number of damaged  o-rings); `number` (number of o-rings each launch), and `incident` (indicates whether at least one o-ring was damaged (1) or if no o-rings were damaged (0)).

```{r}
chall <- read.csv("http://people.carleton.edu/~kstclair/data/challenger.csv")
```


### (5a) Recreate Figure 1b by plotting the number of damaged o-rings vs. temperature. You will need to jitter the points since some overlap so use `geom_jitter(height = .05)`. Why does omitting the 0 damage incident flights (Figure 1a) obscure the relationship between temperature and o-ring performance?

```{r}
ggplot(chall, aes(x = temperature, y = damaged)) +
  geom_point() + 
  geom_smooth(method="lm", se=FALSE, color="red") + 
  geom_jitter(height = .05)
```
This is due to the fact that there are more 0 damage incident flights for higher temperatures, with all 0 damage incident flights occurring above 65 degrees. Therefore, removing these points removes this observed relationship.

### (5b)  The first regression model considered in section 3.1 was a  regression for the number of damaged o-rings. Given a particular temperature and pressure (X-values), we model $Y=$ the number damaged  as a binomial random variable with parameters $m$ and $\pi(X)$. What is $m$ equal to for this model? What is $\pi(X)$ the probability of?

The $m$ is the total number of O-rings and the $\pi(X)$ value is the probability that an o-ring will be damaged at a particular temperature and pressure.

### (5c)   Fit the  logistic regression of `damaged` on `temperature` and `pressure`. (You can verify that your coefficient estimates, SEs, and residual deviance match the article's numbers (pg. 948).) Is temperature significance after accounting for pressure? Is pressure significance after accounting for temperature?

$$logit(\pi(X)) = 13.292 - 0.229temperature + 0.0104pressure$$
```{r}
#(5c) code
chall2 <- chall %>%
      mutate(damaged = ifelse(damaged == "0",0,1))
chall_glm <- glm(damaged ~ temperature + pressure, family = binomial, data = chall2)
summary(chall_glm, conf.int = TRUE)
challtemp_glm <- glm(damaged ~ pressure, family = binomial, data = chall2)
anova(challtemp_glm, chall_glm, test = "Chisq")
challpressure_glm <- glm(damaged ~ temperature, family = binomial, data = chall2)
anova(challpressure_glm, chall_glm, test = "Chisq")
summary(chall_glm, conf.int = TRUE)
1-pchisq(18.782, df=20)
```
Pressure is statistically significant after accounting for temperature (p-value = 000536). Temperature is not statistically significant after accounting for pressure (p-value = 0.216).

### (5d)   Conduct a goodness-of-fit test for the part (c) model. Do we have any evidence for extra-binomial variation? Can we trust this test result? (e.g. are the assumptions needed to trust this test met?)

We get a deviance of $G^2 = 18.782$ with a p-value of 0.536. Since our p-value is high, we can reject the null hypothesis and conclude that we have insufficient evidence for extra-binomial variation. As such, we can trust this test.

### (5e)    Fit the  logistic regression of `damaged` on  `temperature` and use this model to plot the estimated probability of o-ring failure as a function of temperature for temps ranging from 30 to 90 degrees. To extend the `geom_smooth` to these limits, add the layers `xlim(30, 90) + ylim(0,1)` *before* the `geom_smooth` and add the argument `fullrange=TRUE` to `geom_smooth`.

```{r}
ggplot(chall2, aes(x = temperature, y = damaged)) + 
   geom_point() + 
   xlim(30, 90) + 
   ylim(0,1) + 
   geom_smooth(method="glm", method.args = list(family=binomial), se=FALSE, fullrange = TRUE)
```

### (5f)   Use your model from part (e) to predict the probability that an o-ring fails at a temperature of 31 degrees (the temp the morning of the Challenger launch). Knowing that o-ring failure can result in catastrophic damage, would you have advised NASA to launch the Challenger that morning? 


$$\pi(X, temp = 31) = \frac{e^{15.043}e^{-.232(31)}}{1 + e^{15.043}e^{-.232(32)}} = \frac{e^{7.845}}{1 + e^{7.845}} = 0.9996$$.

Since the estimated probability that an o-ring fails at a temperature of 31 degrees is 0.9996, and we know that O-ring results in catastrophic damage, I would have advised NASA to not launch that morning.

```{r}
challpressure_glm <- glm(damaged ~ temperature, family = binomial, data = chall2)
summary(challpressure_glm, conf.int = TRUE)
exp(7.8447)/(1 + exp(7.8447))
```
